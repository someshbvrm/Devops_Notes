
---

# âš¡ Kubernetes Scheduling & Availability

---

## ğŸ–¥ï¸ Node Maintenance

### ğŸ”¹ Drain a Node

Safely evict all pods before maintenance (e.g., kernel upgrades, reboot).

```bash
kubectl drain <node-name> --ignore-daemonsets
```

* âœ… Marks node **unschedulable**
* âœ… Respects **PodDisruptionBudgets (PDBs)**
* âŒ DaemonSets are not evicted (unless forced)

ğŸ‘‰ After maintenance, make the node schedulable again:

```bash
kubectl uncordon <node-name>
```

---

## ğŸ·ï¸ Labels for Scheduling

Attach labels to nodes:

```bash
kubectl label nodes <node-name> disktype=ssd
kubectl label nodes <node-name> project=itcm
kubectl label nodes <node-name> project=boa
```

Check labels:

```bash
kubectl get nodes --show-labels
```

---

## ğŸ¯ Scheduling Rules

### ğŸ”¹ NodeSelector (Simple Matching)

Schedule Pod on a node with a matching label.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
  nodeSelector:
    disktype: ssd
```

---

### ğŸ”¹ NodeName (Direct Binding)

Force Pod to a specific node by name.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: foo-node   # Specific node name
  containers:
  - name: nginx
    image: nginx
```

---

### ğŸ”¹ Node Affinity (Flexible Rules)

* `requiredDuringSchedulingIgnoredDuringExecution` â†’ Hard rule
* `preferredDuringSchedulingIgnoredDuringExecution` â†’ Soft rule

ğŸ‘‰ Example:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values:
            - antarctica-east1
            - antarctica-west1
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: another-node-label-key
            operator: In
            values:
            - another-node-label-value
  containers:
  - name: pause
    image: registry.k8s.io/pause:3.8
```

---

### âš–ï¸ Node Affinity with Weights

Nodes are scored by weights â†’ higher scores are prioritized.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-affinity-preferred-weight
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/os
            operator: In
            values:
            - linux
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: label-1
            operator: In
            values:
            - key-1
      - weight: 50
        preference:
          matchExpressions:
          - key: label-2
            operator: In
            values:
            - key-2
  containers:
  - name: pause
    image: registry.k8s.io/pause:3.8
```

---

## ğŸ¤ Pod Affinity & Anti-Affinity

* **Pod Affinity** â†’ Pods like to co-locate with others
* **Pod Anti-Affinity** â†’ Pods avoid co-locating

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values:
            - S1
        topologyKey: topology.kubernetes.io/zone
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: security
              operator: In
              values:
              - S2
          topologyKey: topology.kubernetes.io/zone
  containers:
  - name: pause
    image: registry.k8s.io/pause:3.8
```

---

## ğŸš« Taints & Tolerations

* **Taints (Node)** â†’ Repel pods ğŸš·
* **Tolerations (Pod)** â†’ Allow pods to run despite taints

### Taint Node

```bash
kubectl taint nodes node1 reserved=itcm:NoSchedule
```

### Pod with Toleration

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
  tolerations:
  - key: "reserved"
    operator: "Equal"
    value: "itcm"
    effect: "NoSchedule"
```

---

## ğŸ›¡ï¸ PodDisruptionBudgets (PDB)

Ensure availability during **voluntary disruptions** (e.g., `drain`, upgrades).

### Example with `minAvailable`

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: zk-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: zookeeper
```

### Example with `maxUnavailable`

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: zk-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: zookeeper
```

Check PDBs:

```bash
kubectl get poddisruptionbudgets
```

---

âœ¨ **Summary**

* âœ… **NodeSelector / Node Affinity** â†’ Where Pods *should* run
* âœ… **Taints & Tolerations** â†’ Where Pods *shouldnâ€™t* run
* âœ… **Pod Affinity/Anti-Affinity** â†’ Pods scheduling based on other Pods
* âœ… **PDB** â†’ Keep apps available during maintenance

---


# ğŸ“Š Kubernetes Scheduling & Availability â€“ Comparison Table

| ğŸ”§ Feature                       | ğŸ“ Scope    | âœ… What it Does                                                  | âš ï¸ Limitation                                     | ğŸ“ Example Usage                                 |
| -------------------------------- | ----------- | --------------------------------------------------------------- | ------------------------------------------------- | ------------------------------------------------ |
| **NodeSelector** ğŸ·ï¸             | Node labels | Schedule pods on nodes matching exact labels                    | Very basic, only supports equality-based matching | `nodeSelector: disktype=ssd`                     |
| **Node Affinity** ğŸ¯             | Node labels | Advanced rules (In, NotIn, Exists, etc.), soft/hard constraints | Pod wonâ€™t move if node labels change              | Schedule only on nodes in `zone=us-east1`        |
| **Pod Affinity** ğŸ¤              | Other Pods  | Schedule pods *together* with pods that have specific labels    | Risk of overloading certain nodes                 | Place frontend pod with backend pod in same zone |
| **Pod Anti-Affinity** ğŸ™…         | Other Pods  | Ensure pods *donâ€™t* run with other specific pods                | Can reduce scheduling flexibility                 | Spread replicas across zones/nodes               |
| **Taints** ğŸš«                    | Node-level  | Repel pods from nodes unless tolerated                          | Alone doesnâ€™t guarantee scheduling                | Reserve nodes for system workloads               |
| **Tolerations** ğŸ›¡ï¸              | Pod-level   | Allow pods to tolerate tainted nodes                            | Doesnâ€™t *force* scheduling                        | Critical pods run on tainted infra nodes         |
| **PodDisruptionBudget (PDB)** ğŸ›‘ | Workloads   | Ensures min availability during voluntary disruptions           | Doesnâ€™t protect from node crashes                 | Keep 4/5 replicas running during upgrade         |
| **kubectl drain** ğŸ§¹             | Node        | Safely evict pods before maintenance                            | Evicts only voluntary workloads (respects PDB)    | `kubectl drain node1 --ignore-daemonsets`        |

---

âš¡ **Quick Rules to Remember**:

* Use **NodeSelector/NodeAffinity** â†’ control **where pods run**.
* Use **Taints & Tolerations** â†’ control **where pods donâ€™t run**.
* Use **Pod Affinity/Anti-Affinity** â†’ control **pod-to-pod co-location**.
* Use **PDB** â†’ control **availability during maintenance**.

---
